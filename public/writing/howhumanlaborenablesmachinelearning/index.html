<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>How Human Labor Enables Machine Learning | Stephanie Kirmer</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="Much of the division between technology and human activity is artificial — how do people make our work possible?
We don’t talk enough about how much manual, human work we rely upon to make the exciting advances in ML possible. The truth is, the division between technology and human activity is artificial. All the inputs that make models are the result of human effort, and all the outputs in one way or another exist to have an impact on people.">
    <meta name="generator" content="Hugo 0.120.3">
    
    
    
    
      <meta name="robots" content="noindex, nofollow">
    

    
<link rel="stylesheet" href="/quickstart/ananke/css/main.min.css" >



    
    
    
      

    

    
    
    <meta property="og:title" content="How Human Labor Enables Machine Learning" />
<meta property="og:description" content="Much of the division between technology and human activity is artificial — how do people make our work possible?
We don’t talk enough about how much manual, human work we rely upon to make the exciting advances in ML possible. The truth is, the division between technology and human activity is artificial. All the inputs that make models are the result of human effort, and all the outputs in one way or another exist to have an impact on people." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://skirmer.github.io/quickstart/writing/howhumanlaborenablesmachinelearning/" /><meta property="article:section" content="writing" />



<meta itemprop="name" content="How Human Labor Enables Machine Learning">
<meta itemprop="description" content="Much of the division between technology and human activity is artificial — how do people make our work possible?
We don’t talk enough about how much manual, human work we rely upon to make the exciting advances in ML possible. The truth is, the division between technology and human activity is artificial. All the inputs that make models are the result of human effort, and all the outputs in one way or another exist to have an impact on people.">

<meta itemprop="wordCount" content="1953">
<meta itemprop="keywords" content="human-ai-collaboration,editors-pick,artificial-intelligence,large-language-models,machine-learning," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="How Human Labor Enables Machine Learning"/>
<meta name="twitter:description" content="Much of the division between technology and human activity is artificial — how do people make our work possible?
We don’t talk enough about how much manual, human work we rely upon to make the exciting advances in ML possible. The truth is, the division between technology and human activity is artificial. All the inputs that make models are the result of human effort, and all the outputs in one way or another exist to have an impact on people."/>

	
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  
  <header class="cover bg-top" style="background-image: url('https://cdn-images-1.medium.com/max/1024/0*m8kDZa-npmtH6ukB');">
    <div class="bg-black-60">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/quickstart/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        Stephanie Kirmer
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/quickstart/about/" title=" page">
              
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/quickstart/speaking/" title="Speaking page">
              Speaking
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/quickstart/writing/" title="Writing page">
              Writing
            </a>
          </li>
          
        </ul>
      
      
<div class="ananke-socials">
  
    
    <a href="http://github.com/skirmer" target="_blank" rel="noopener" class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="GitHub link" aria-label="follow on GitHub——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
    
    <a href="http://linkedin.com/in/skirmer" target="_blank" rel="noopener" class="linkedin ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" aria-label="follow on LinkedIn——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
    
    <a href="https://medium.com/@s.kirmer" target="_blank" rel="noopener" class="medium ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="Medium link" aria-label="follow on Medium——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 170 170;" version="1.1" viewBox="0 0 170 170"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M46.5340803,65.2157554 C46.6968378,63.6076572 46.0836,62.018231 44.8828198,60.93592 L32.6512605,46.2010582 L32.6512605,44 L70.6302521,44 L99.9859944,108.380952 L125.794585,44 L162,44 L162,46.2010582 L151.542017,56.2281011 C150.640424,56.9153477 150.193188,58.0448862 150.380019,59.1628454 L150.380019,132.837155 C150.193188,133.955114 150.640424,135.084652 151.542017,135.771899 L161.755369,145.798942 L161.755369,148 L110.38282,148 L110.38282,145.798942 L120.963119,135.527337 C122.002801,134.487948 122.002801,134.182246 122.002801,132.592593 L122.002801,73.0417402 L92.585901,147.755438 L88.6106443,147.755438 L54.3622782,73.0417402 L54.3622782,123.115814 C54.0767278,125.221069 54.7759199,127.3406 56.2581699,128.863022 L70.0186741,145.55438 L70.0186741,147.755438 L31,147.755438 L31,145.55438 L44.7605042,128.863022 C46.2319621,127.338076 46.8903838,125.204485 46.5340803,123.115814 L46.5340803,65.2157554 Z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
</div>

    </div>
  </div>
</nav>

      <div class="tc-l pv6 ph3 ph4-ns">
        
          <div class="f2 f1-l fw2 white-90 mb0 lh-title">How Human Labor Enables Machine Learning</div>
          
        
      </div>
    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        WRITING
      </aside>
      










  <div id="sharing" class="mt3 ananke-socials">
    
      
      <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://skirmer.github.io/quickstart/writing/howhumanlaborenablesmachinelearning/&amp;title=How%20Human%20Labor%20Enables%20Machine%20Learning" class="ananke-social-link linkedin no-underline" aria-label="share on LinkedIn">
        
        <span class="icon"> <svg style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span>
        
      </a>
    
  </div>


      <h1 class="f1 athelas mt3 mb1">How Human Labor Enables Machine Learning</h1>
      
      
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><h4 id="heading"></h4>
<p>Much of the division between technology and human activity is artificial — how do people make our work possible?</p>
<p>We don’t talk enough about how much manual, human work we rely upon to make the exciting advances in ML possible. The truth is, the division between technology and human activity is artificial. All the inputs that make models are the result of human effort, and all the outputs in one way or another exist to have an impact on people. I’m using today’s column to talk about some of the specific areas in which we overlook how important people are to what we do — and not just the data scientists who write the code.</p>
<blockquote>
<p>The division between technology and human activity is artificial, because all the inputs that make models are the result of human effort, and all the outputs in one way or another exist to have an impact on people.</p>
</blockquote>
<h3 id="heading-1"></h3>
<p>Generating Data</p>
<p>You almost certainly already know this one — LLMs require extraordinary quantities of text data to train. We often think about this in hundreds or thousands of gigabytes of data on a hard drive, but this is a bit abstract. Some reports indicate that GPT-4 had on the order of
<em>1 trillion</em>
words in its training data. Every one of those words was written by a person, out of their own creative capability. For context, book 1 in the Game of Thrones series was about 292,727 words. So, the training data for GPT-4 was about
<em>3,416,152 copies of that book long</em>
. And this is only an example from text modeling — other kinds of models, like those that generate or classify multimedia, use similarly massive volumes of those sorts of data too.</p>
<p>There are a few things to consider when this data is concerned. First, all that data is generated by people, it doesn’t just appear on our hard drives by magic. Respecting and acknowledging the people who create our data is important just as a matter of ethics, because they have put in work and created value that we are benefiting from. But there are also more selfish reasons why we ought to know where our data comes from. We have a responsibility as data scientists to know what material we are giving to our models as exemplars, and to understand it in great depth. If we ignore the provenance of our data, we open ourselves up to being unpleasantly surprised by how our models behave when faced with the real world. For example, training LLMs on internet forums or social media data leads these models to a risk of replicating the worst of these spaces, including racism, hate speech, and more. In somewhat less extreme examples, we know that
<a href="https://www.technologyreview.com/2023/08/07/1077324/ai-language-models-are-rife-with-political-biases/">models are flavored by the training data they get</a>
.</p>
<blockquote>
<p>If we ignore the provenance of our data, we open ourselves up to being unpleasantly surprised by how our models behave when faced with the real world.</p>
</blockquote>
<h3 id="heading-2"></h3>
<p>Labeling Data</p>
<p>Human help is required to label data. But, what are labels exactly? At its core, labeling data means using human discernment to assign values or judgments to what we uncover in the data. No matter how data is collected or created, a great many of the machine learning use cases for such data require labeling of some kind.</p>
<p>This may mean simply deciding whether a datapoint is good or bad, determining whether words are positive or negative, creating derived values, dividing records into categories, determining what tags apply to an image or video, or endless others. One common example is identifying what text is in an image or other multimedia to improve character recognition models.
<a href="https://www.hcaptcha.com/labeling">If you have used captcha</a>
, I bet this sounds familiar — you’ve done data labeling work.</p>
<p>LLMs themselves, in theory, don’t require labeling, because we infer the quality of human-ness of the texts from the fact that these texts were already generated by real people and thus must be as ‘similar to human output’ as they can possibly be, in essence. Basically, because a human wrote it, then it’s by definition an acceptable example for the model to try and learn and emulate. This is where we use things like semantic embedding — the model learns how the language patterns work in human-generated text and quantifies these into mathematical representations. But we are still choosing which text goes in to the model’s processes, as I described earlier, and we have a responsibility to understand and assess that text.</p>
<h3 id="heading-3"></h3>
<p>Teaching Models</p>
<p>Reinforcement learning uses human intervention for tasks around tuning — meaning, we’re adjusting how the model responds to prompts slightly, once it’s basically got the hang of returning a coherent answer, whether that’s text, or images, or video, or other things. After some mainly automated element of pre-training or base training,
<a href="https://www.youtube.com/watch?v=bZQun8Y4L2A">many models are fine tuned by human beings, making sometimes subtle determinations of whether model is doing what was desired.</a>
This is a very hard task, because the nuances of what we actually want from the model can be really complicated. It’s basically copy-editing an LLM in a pass-fail fashion, at a massive scale.</p>
<p>As I have discussed before, many modern models are seeking to produce the content that will be most pleasing to a human user- something that will seem right and appealing to a human being. What better way to train this then, than asking human beings to look at the results of an intermediate stage of training and decide whether the results are fitting this description, and tell the model so it can make more appropriate choices? Not only is that the most effective way, but it may be the only way it can work.</p>
<blockquote>
<p>It’s basically copy-editing an LLM in a pass-fail fashion.</p>
</blockquote>
<h3 id="heading-4"></h3>
<p>Why this matters</p>
<p>Ok, so what? Is it enough to be conscientious about the fact that real people do a lot of hard work to make our models possible? Pat them on the back and say thanks? No, not quite, because we need to interrogate what the human influence means for the results we generate. As data scientists, we need to be curious about the interaction between what we build and the rest of the world in which it lives.</p>
<p>Because of all these areas of influence, human choices shape the model capabilities and judgments. We embed human bias into the models, because humans create, control, and judge all the material involved. We decide that this bit of text will be provided to the model for training, or that this specific response from the model is worse than another, and the model solidifies these choices of ours into mathematical representations that it can reuse and replicate.</p>
<p>This element of bias is inevitable, but it’s not necessarily bad. Looking to create something free of all human influence suggests that human influence and human beings themselves are problems to be avoided, which isn’t a fair assessment in my opinion. At the same time, we should be realistic about the fact that human bias is part of our models, and resist the temptation to view models as beyond our human foibles. Things like how we assign labels, for example, lead us to imbue meanings into the data consciously or subconsciously. We leave traces of our thought processes and our histories in the data we create, whether it’s original creative content, data labels, or judgments of model output.</p>
<blockquote>
<p>Looking to create something free of all human influence suggests that human influence and human beings themselves are problems to be avoided, which isn’t a fair assessment in my opinion.</p>
</blockquote>
<p>In addition, often in the machine learning space human effort is perceived as in service of “real” work instead of meaningful on its own. People who produce original work stop being seen as uniquely creative individuals, but just get folded into “content generators” in service of the model. We lose track of the humanity and real reason that this content exists, which is to serve and empower humanity. As with the previous point, we end up devaluing people in favor of idolizing technology, which I think is foolish. The models are the product of people and exist to serve people, they aren’t an independent end unto themselves. If you build a model that is never used and never gets run, what is the point?</p>
<h3 id="heading-5"></h3>
<p>Is data a renewable resource?</p>
<p>There is another interesting issue: the risk of running out of pristine human generated content as a limiter on model capability. That is, as our society begins to use LLMs to generate our data, and Dall-E to generate our images, and we stop incentivizing real people to be creative without these technologies, then the trillions of words and mountains of images we need to train new versions of these models will become contaminated with artificially generated content. That content, of course, is derived from human content, but it’s not the same. We don’t yet have very good ways to differentiate content that’s generated by people without models, so we’re going to struggle to know whether our training data for future models has this contamination in it, and how much.</p>
<p>Some people argue this is not actually a big deal, and that training models on at least some proportion artificial content won’t be a problem, but others theorize that when
<a href="https://bdtechtalks.com/2023/06/19/chatgpt-model-collapse/">we start to cannibalize artificially generated content in this way, the underlying processes of training will be existentially altered, in the form of something called Model Collapse</a>
. This is in some ways an example of the essential problem that your model affects the world that your model relies on, so the model is definitionally changed by its own behavior. This isn’t just true of LLMs, as data scientists know too well. Any model can work itself out of a job by affecting how people behave, resulting in performance drift due to underlying data relationships shifting.</p>
<blockquote>
<p>Your model affects the world that your model relies on, so the model is definitionally changed by its own behavior.</p>
</blockquote>
<p>Even if we aren’t training on actually artificial data, also, there are many scholars considering whether our human composition and creative processes will change due to our exposure to artificially created content. If you read a whole lot of LLM generated text, either while writing and getting a model’s advice or just around the internet in general,
<a href="https://arxiv.org/abs/2309.05196">is that going to subtly change how you write</a>
? It’s too early to know on a community level, but it’s a serious concern.</p>
<p>Human influence is a fact of machine learning—it’s a philosophical issue. We think of machine learning as a pure scientific enterprise, something that acts upon us, and this is one of the reasons it seems terrifying to some. But in reality, the systems that are being created are the product of human intervention, and human creativity. Creating and curating data makes all the rest of machine learning possible. In some ways, this should be comforting to us, because we have control over what we do with machine learning and how we do it. The process of machine learning is taking relationships between pieces of data and calculating them into mathematical representations, but the data is produced by people and is under our control. Machine learning and AI aren’t some alien, abstract force —
<strong>they’re just us.</strong></p>
<p><em>See more of my work at</em>
<a href="http://www.stephaniekirmer.com/"><em>www.stephaniekirmer.com</em></a>
<em>.</em></p>
<p>Articles and references linked above, for easy access:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=bZQun8Y4L2A">https://www.youtube.com/watch?v=bZQun8Y4L2A</a>
The State of GPT, Microsoft Build Conference 2023, Andrej Karpathy</li>
<li><a href="https://www.technologyreview.com/2023/08/07/1077324/ai-language-models-are-rife-with-political-biases/">www.technologyreview.com%2F2023%2F08%2F07%2F1077324%2Fai-language-models-are-rife-with-political-biases%2F</a>
MIT Technology Review,
<a href="https://www.technologyreview.com/author/melissa-heikkila/">Melissa Heikkilä</a>
, August 2023</li>
<li><a href="https://www.hcaptcha.com/labeling">https://www.hcaptcha.com/labeling</a></li>
<li><a href="https://files.eric.ed.gov/fulltext/EJ1390465.pdf">https://files.eric.ed.gov/fulltext/EJ1390465.pdf</a></li>
<li><a href="https://arxiv.org/abs/2309.05196">https://arxiv.org/abs/2309.05196</a></li>
<li><a href="https://bdtechtalks.com/2023/06/19/chatgpt-model-collapse/">https://bdtechtalks.com/2023/06/19/chatgpt-model-collapse/</a></li>
</ul>
<hr>
<p><a href="https://towardsdatascience.com/how-human-labor-enables-machine-learning-367feee8bc91">How Human Labor Enables Machine Learning</a>
was originally published in
<a href="https://towardsdatascience.com">Towards Data Science</a>
on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>
<ul class="pa0">
  
   <li class="list di">
     <a href="/quickstart/tags/human-ai-collaboration/" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">human-ai-collaboration</a>
   </li>
  
   <li class="list di">
     <a href="/quickstart/tags/editors-pick/" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">editors-pick</a>
   </li>
  
   <li class="list di">
     <a href="/quickstart/tags/artificial-intelligence/" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">artificial-intelligence</a>
   </li>
  
   <li class="list di">
     <a href="/quickstart/tags/large-language-models/" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">large-language-models</a>
   </li>
  
   <li class="list di">
     <a href="/quickstart/tags/machine-learning/" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">machine-learning</a>
   </li>
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




  <div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
    <p class="f5 b mb3">Related</p>
    <ul class="pa0 list">
	   
	     <li  class="mb2">
          <a href="/quickstart/writing/whatdoesitmeanwhenmachinelearningmakesamistake/">What Does It Mean When Machine Learning Makes a Mistake?</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/quickstart/writing/isgenerativeaitakingovertheworld/">Is Generative AI Taking Over the World?</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/quickstart/writing/archetypesofthedatascientistrole/">Archetypes of the Data Scientist Role</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/quickstart/writing/machinelearningengineers-whatdotheyactuallydo/">Machine Learning Engineers — what do they actually do?</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/quickstart/writing/machinelearningspublicperceptionproblem/">Machine Learning’s Public Perception Problem</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/quickstart/writing/settinghealthyboundariesgeneratinggeofencesatscalewithmachinelearningpart1/">Setting Healthy Boundaries: Generating Geofences at Scale with Machine Learning (Part 1)</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/quickstart/writing/settinghealthyboundariesgeneratinggeofencesatscalewithmachinelearningpart2/">Setting Healthy Boundaries: Generating Geofences at Scale with Machine Learning (Part 2)</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/quickstart/writing/thinkingsociologicallyaboutmachinelearning/">Thinking Sociologically About Machine Learning</a>
        </li>
	    
    </ul>
</div>

</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://skirmer.github.io/quickstart/" >
    &copy;  Stephanie Kirmer 2023 
  </a>
    <div>
<div class="ananke-socials">
  
    
    <a href="http://github.com/skirmer" target="_blank" rel="noopener" class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="GitHub link" aria-label="follow on GitHub——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
    
    <a href="http://linkedin.com/in/skirmer" target="_blank" rel="noopener" class="linkedin ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" aria-label="follow on LinkedIn——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
    
    <a href="https://medium.com/@s.kirmer" target="_blank" rel="noopener" class="medium ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="Medium link" aria-label="follow on Medium——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 170 170;" version="1.1" viewBox="0 0 170 170"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M46.5340803,65.2157554 C46.6968378,63.6076572 46.0836,62.018231 44.8828198,60.93592 L32.6512605,46.2010582 L32.6512605,44 L70.6302521,44 L99.9859944,108.380952 L125.794585,44 L162,44 L162,46.2010582 L151.542017,56.2281011 C150.640424,56.9153477 150.193188,58.0448862 150.380019,59.1628454 L150.380019,132.837155 C150.193188,133.955114 150.640424,135.084652 151.542017,135.771899 L161.755369,145.798942 L161.755369,148 L110.38282,148 L110.38282,145.798942 L120.963119,135.527337 C122.002801,134.487948 122.002801,134.182246 122.002801,132.592593 L122.002801,73.0417402 L92.585901,147.755438 L88.6106443,147.755438 L54.3622782,73.0417402 L54.3622782,123.115814 C54.0767278,125.221069 54.7759199,127.3406 56.2581699,128.863022 L70.0186741,145.55438 L70.0186741,147.755438 L31,147.755438 L31,145.55438 L44.7605042,128.863022 C46.2319621,127.338076 46.8903838,125.204485 46.5340803,123.115814 L46.5340803,65.2157554 Z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
</div>
</div>
  </div>
</footer>

  </body>
</html>
